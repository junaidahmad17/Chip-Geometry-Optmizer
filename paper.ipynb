{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow  as tf\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Environemt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "train_data_path = os.getenv('TRAIN_DATA_PATH')\n",
    "test_data_path = os.getenv('TEST_DATA_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(train_data_path, usecols=['Xs', 'Ys', 'Wafer_Size', 'No_of_Chips'])\n",
    "X = df[['Xs', 'Ys', 'Wafer_Size']]\n",
    "y = df['No_of_Chips']\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_scaler = preprocessing.RobustScaler()\n",
    "X_sc = rb_scaler.fit_transform(X)\n",
    "col_names = ['Xs', 'Ys', 'Wafer_Size']\n",
    "X_sc = pd.DataFrame(X_sc, columns=col_names)\n",
    "df_sc = X_sc\n",
    "df_sc['No_of_Chips'] = y\n",
    "df_sc.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = pd.read_excel(test_data_path)\n",
    "test_list.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[['Xs', 'Ys', 'Wafer_Size']]\n",
    "y_train = y\n",
    "X_test = test_list.drop(['No_of_Chips'], axis=1)\n",
    "y_test = test_list['No_of_Chips']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "## Scaling training features\n",
    "X_train_sc = rb_scaler.fit_transform(X_train)\n",
    "col_names = ['Xs', 'Ys', 'Wafer_Size']\n",
    "X_train_sc = pd.DataFrame(X_train_sc, columns=col_names)\n",
    "\n",
    "## Scaling testing features\n",
    "X_test_sc = rb_scaler.fit_transform(X_test)\n",
    "col_names = ['Xs', 'Ys', 'Wafer_Size']\n",
    "X_test_sc = pd.DataFrame(X_test_sc, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot original distribution plot\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
    "ax1.set_title('Original Distributions')\n",
    "\n",
    "sns.kdeplot(X['Xs'], ax=ax1)\n",
    "sns.kdeplot(X['Ys'], ax=ax1)\n",
    "sns.kdeplot(X['Wafer_Size'], ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scaled distribution plot\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
    "ax1.set_title('Scaled Distributions')\n",
    "\n",
    "sns.kdeplot(X_sc['Xs'], ax=ax1)\n",
    "sns.kdeplot(X_sc['Ys'], ax=ax1)\n",
    "sns.kdeplot(X_sc['Wafer_Size'], ax=ax1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr(alpha, l1_ratio, exp_name):\n",
    "    mlflow.sklearn.autolog(disable=True)\n",
    "    mlflow.set_experiment(exp_name)\n",
    "    with mlflow.start_run(run_name='LR-basic'):\n",
    "        params = {\n",
    "            'alpha': alpha,\n",
    "            'l1_ratio':l1_ratio,\n",
    "        }\n",
    "\n",
    "        mlflow.set_tag('model_name', 'LR')\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        lr = ElasticNet(alpha=params['alpha'], l1_ratio=params['l1_ratio'], random_state=42)\n",
    "        lr.fit(X_train_sc, y_train)\n",
    "\n",
    "        ################################      TRAIN      ##########################################################\n",
    "        # Infer model signature\n",
    "        predictions_train = lr.predict(X_train_sc)\n",
    "        signature = infer_signature(X_train_sc, predictions_train)\n",
    "        \n",
    "        (rmse, mae, r2) = eval_metrics(y_train, predictions_train)\n",
    "        print('train>')\n",
    "        print(\"Elasticnet model (alpha={:f}, l1_ratio={:f}):\".format(alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        mlflow.log_metric(\"rmse_tr\", rmse)\n",
    "        mlflow.log_metric(\"r2_tr\", r2)\n",
    "        mlflow.log_metric(\"mae_tr\", mae)\n",
    "\n",
    "        ##############################      TEST        ######################################\n",
    "        predictions_test = lr.predict(X_test_sc)\n",
    "\n",
    "        mlflow.sklearn.log_model(lr, \"lr-model\", signature=signature)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(y_test, predictions_test)\n",
    "\n",
    "        print('test>')\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        return predictions_train, predictions_test\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "l1s = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "for alpha in alphas:\n",
    "    for l1 in l1s:\n",
    "        train_pred, test_pred = train_lr(alpha, l1, exp_name='LR-corr')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 100, 150, 300],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [3, 6, 9, 12, 15, 18],\n",
    "    'max_leaf_nodes': [3, 6, 9, 12, 15, 18],\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestRegressor(),\n",
    "                           param_grid=param_grid)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(n_estimators, max_features, max_depth, max_leaf_nodes, exp_name):\n",
    "    mlflow.sklearn.autolog(disable=True)\n",
    "    mlflow.set_experiment(exp_name)\n",
    "    with mlflow.start_run(run_name='RF-basic'):\n",
    "        params = {\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'max_leaf_nodes': max_leaf_nodes\n",
    "            }\n",
    "        mlflow.set_tag('model_name', 'RF')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        rf = RandomForestRegressor(n_estimators=params['n_estimators'], max_depth=params[\"max_depth\"], max_features=5)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        predictions_train = rf.predict(X_train)\n",
    "        signature = infer_signature(X_train, predictions_train)\n",
    "        (rmse, mae, r2) = eval_metrics(y_train, predictions_train)\n",
    "\n",
    "        print(\"RandomForestsRegressor (n_estimators={:d}, max_depth={:d}):\".format(params[\"n_estimators\"], params[\"max_depth\"]))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "        mlflow.log_metric(\"rmse_tr\", rmse)\n",
    "        mlflow.log_metric(\"r2_tr\", r2)\n",
    "        mlflow.log_metric(\"mae_tr\", mae)\n",
    "\n",
    "        print('----------------------------------------------------------------------------------------------------------------------')\n",
    "        predictions_test = rf.predict(X_test)\n",
    "        (rmse, mae, r2) = eval_metrics(y_test, predictions_test)\n",
    "\n",
    "        print(\"RandomForestsRegressor (n_estimators={:d}, max_depth={:d}):\".format(params[\"n_estimators\"], params[\"max_depth\"]))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        return predictions_train, predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_estimators = param_grid['n_estimators']\n",
    "Max_features = param_grid['max_features']\n",
    "Max_depth = param_grid['max_depth']\n",
    "Max_leaf_nodes = param_grid['max_leaf_nodes']\n",
    "\n",
    "for n_estimators in N_estimators:\n",
    "    for max_features in Max_features:\n",
    "        for max_depth in Max_depth:\n",
    "            for max_leaf_nodes in Max_leaf_nodes:\n",
    "                train_pred, test_pred = train_rf(n_estimators, max_features, max_depth, max_leaf_nodes, 'RF-corr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5, 8, 10],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0,],\n",
    "        'max_depth': [3, 4, 5, 6, 7, 8]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=params,\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    n_jobs = 10,\n",
    "    cv = 10,\n",
    "    verbose=True,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(min_child_weight=1, gamma=8, subsample=0.8, colsample_bytree=1.0, max_depth=5, exp_name='XGB'):\n",
    "    mlflow.sklearn.autolog(disable=True)\n",
    "    mlflow.set_experiment(exp_name)\n",
    "    with mlflow.start_run(run_name='XGB-basic'):\n",
    "        params = {\n",
    "                'min_child_weight': min_child_weight,\n",
    "                'gamma': gamma,\n",
    "                'subsample': subsample,\n",
    "                'colsample_bytree': colsample_bytree,\n",
    "                'max_depth': max_depth\n",
    "            }\n",
    "        mlflow.set_tag('model_name', 'XGB')\n",
    "        mlflow.log_params(params)\n",
    "        xgb_model = xgb.XGBRegressor(\n",
    "            n_estimators=50,\n",
    "            reg_lambda=1,\n",
    "            gamma=0,\n",
    "            max_depth=2\n",
    "        )\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        # make predictions for test data\n",
    "        y_pred = xgb_model.predict(X_train)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(y_train, predictions)\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "        mlflow.log_metric(\"rmse_tr\", rmse)\n",
    "        mlflow.log_metric(\"r2_tr\", r2)\n",
    "        mlflow.log_metric(\"mae_tr\", mae)\n",
    "\n",
    "        print('----------------------------------------------------------------------------------------------------------------------')\n",
    "        y_pred = xgb_model.predict(X_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        (rmse, mae, r2) = eval_metrics(y_test, predictions)\n",
    "\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Min_child_weight = params['min_child_weight']\n",
    "Gamma = params['gamma']\n",
    "Subsample = params['subsample']\n",
    "Colsample_bytree = params['colsample_bytree']\n",
    "Max_depth = params['max_depth']\n",
    "\n",
    "for min_child_weight in Min_child_weight:\n",
    "    for gamma in Gamma:\n",
    "        for subsample in Subsample:\n",
    "            for colsample_bytree in Colsample_bytree:\n",
    "                for max_depth in Max_depth:\n",
    "                    train_xgb(min_child_weight, gamma, subsample, colsample_bytree, max_depth, 'XGB-corr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm, L1, L2, LR):\n",
    "  model = tf.keras.Sequential([\n",
    "      norm,\n",
    "      tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=L1, l2=L2)),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(32, activation='relu'),\n",
    "      tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(LR)) \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DNN(epochs=5000, l1=0, l2=0, lr=0.001, exp_name='DNN'):\n",
    "    mlflow.sklearn.autolog(disable=True)\n",
    "    mlflow.set_experiment(exp_name)\n",
    "    with mlflow.start_run(run_name='DNN'):\n",
    "        params = {\n",
    "            'epochs': epochs,\n",
    "            'l1':l1,\n",
    "            'l2':l2,\n",
    "            'lr':lr\n",
    "        }\n",
    "\n",
    "        mlflow.set_tag('model_name', 'DNN')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        X_normalizer = tf.keras.layers.Normalization(input_shape=[3,], axis=None, )\n",
    "        X_normalizer.adapt(X)\n",
    "\n",
    "\n",
    "        dnn_chips_model = build_and_compile_model(X_normalizer, params['l1'], params['l2'], params['lr'])\n",
    "\n",
    "        history = dnn_chips_model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            validation_split=0.2,\n",
    "            verbose=0, epochs=params['epochs'],)\n",
    "\n",
    "        mlflow.sklearn.log_model(dnn_chips_model, \"model\", registered_model_name=\"DNN-128-R\")\n",
    "\n",
    "        pred = dnn_chips_model.predict(X)\n",
    "        predictions = [p[0] for p in pred]\n",
    "        (rmse, mae, r2) = eval_metrics(y, predictions)\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Shreyas List Test\n",
    "        pred = dnn_chips_model.predict(X_test)\n",
    "        predictions = [p[0] for p in pred]\n",
    "        (rmseS, maeS, r2S) = eval_metrics(y_test, predictions)\n",
    "        print(\"  RMSE: %s\" % rmseS)\n",
    "        print(\"  MAE: %s\" % maeS)\n",
    "        print(\"  R2: %s\" % r2S)\n",
    "\n",
    "        # modelflow logs\n",
    "        mlflow.log_metric(\"rmse_tr\", rmse)\n",
    "        mlflow.log_metric(\"r2_tr\", r2)\n",
    "        mlflow.log_metric(\"mae_tr\", mae)\n",
    "\n",
    "        mlflow.log_metric(\"rmse\", rmseS)\n",
    "        mlflow.log_metric(\"r2\", r2S)\n",
    "        mlflow.log_metric(\"mae\", maeS)\n",
    "        \n",
    "        mlflow.log_metric(\"loss\", min(history.history['loss']))\n",
    "        mlflow.log_metric(\"loss_epoch\", history.history['loss'].index(min(history.history['loss'])))\n",
    "        mlflow.log_metric(\"val_loss\", min(history.history['val_loss']))\n",
    "        mlflow.log_metric(\"val_loss_epoch\", history.history['val_loss'].index(min(history.history['val_loss'])))\n",
    "        \n",
    "        return dnn_chips_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DNN(10000, 0.1, 0.1, 0.001, 'DNN-corr-10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(X_test.columns)\n",
    "print(X_train.columns)\n",
    "model = train_DNN()\n",
    "epochs = 10000\n",
    "l1s = [0, 0.001, 0.01, 0.1, 1]\n",
    "l2s = [0, 0.001, 0.01, 0.1, 1]\n",
    "lrs = [0.001]\n",
    "for l1 in l1s:\n",
    "    for l2 in l2s:\n",
    "        for lr in lrs:\n",
    "            train_DNN(epochs, l1, l2, lr, 'DNN-corr-10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "l1s = [0, 0.001, 0.01, 0.1, 1]\n",
    "l2s = [0, 0.001, 0.01, 0.1, 1]\n",
    "lrs = [0.01]\n",
    "for l1 in l1s:\n",
    "    for l2 in l2s:\n",
    "        for lr in lrs:\n",
    "            train_DNN(epochs, l1, l2, lr, '143-DNN-10000-lr-0.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
